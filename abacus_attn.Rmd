---
title: "Abacus Attention"
author: "Srinivasan, Wagner, Frank, Barner"
date: "January 6, 2016 (revised July 17, 2017)"
output:
  html_document:
    number_sections: yes
    toc: yes
  pdf_document:
    toc: yes
---

<style type="text/css">
body, td {
   font-size: 14px;
}
code {
  font-size: 11px;
}
pre {
  font-size: 11px;
}
</style>

Preliminaries.

```{r}
rm(list=ls())
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(langcog))
suppressPackageStartupMessages(library(lme4))
suppressPackageStartupMessages(library(lmerTest))
library(ggplot2)
library(magrittr)
library(knitr)
library(tidyr)
library(BayesFactor)
opts_chunk$set(fig.width=8, fig.height=5, 
                      echo=TRUE, warning=FALSE, message=FALSE, cache=TRUE)
theme_set(theme_bw())
```

# Experiment 1: Experts with dual task

## Data prep

Read data. Coding info from Katie. 

+ Heaven/Earth 0=Heaven; 1=Earth
+ Condition: 1= In Play; 2=Out of play; 3=leading; 4=trailing
+ Number Requested, 
+ X: 1=Left most column, counting to the right to max of 2 or 3",
+ Y: 1 equals top row (i.e., out of play heavenly bead), counting downwards to 7.
+ Correct on Search task? Trials weith incorrect search responses were excluded from analysis
+ RT
+ Abacus entered: Only relevent to dual task,
+ Correct on Abacus: only relevent to dual task
+ "Number of columns: occasionally you will see 0s in this column, this means the participant was in a pilot version with 4 columns and should be excluded. "
+ Subject Number: Assigned when extracted from .mat instead of alpha numeric number to make some things in life easier,
+ <3Std Dev: removing outliers (2s). Calculated in linear space. Needs to be redone in log space,
+ Inout or Leading trailing trial,
+ Expertise level: ranges from 0 (none) to 2(has used abacus)

```{r}
dual_experts_raw <- read.csv("data/Upright dual data experts w. subject IDs and order.csv")

names(dual_experts_raw) <- c("bead_type", "condition", "number_requested", 
                             "X_pos","Y_pos","search_correct","RT",
                             "abacus_val","abacus_correct","n_col",
                             "subnum","outlier","trial_type",
                             "subid","n_conditions","order","subid_xexpts")
dual_experts_raw %<>% 
  mutate(bead_type = factor(bead_type, 
                            levels = c(0,1), 
                            labels = c("heaven","earth")),
         condition = factor(condition, 
                            levels = c(1,2,3,4), 
                            labels = c("in play", "out of play", 
                                       "leading","trailing")))
```

Exclusions. Filter pilot participants. 

```{r}
pilot_subs <- dual_experts_raw %>%
  group_by(subnum) %>%
  summarise(pilot = any(n_col == 0)) %>%
  filter(pilot) 
  
dual_experts <- filter(dual_experts_raw, 
                       !subnum %in% pilot_subs$subnum)
dual_experts %<>% 
  group_by(subnum) %>%
  mutate(trial_num = 1:n())
```

Check to make sure we have a consistent number of trials, no training trials. 

```{r}
qplot(subnum, trial_num, data = dual_experts)
```

In this dataset we appear to be missing the end of a few participants.

Next, RT exclusions. Note that there are a few 0 RTs. What's the deal with these?

```{r}
sum(dual_experts$RT == 0)
dual_experts %<>% filter(RT > 0, 
                         !is.na(RT))
```

Linear space. 

```{r}
qplot(RT, data = dual_experts, 
      fill = RT > mean(RT) + 3*sd(RT))
mean(dual_experts$RT)
median(dual_experts$RT)
```

Log space looks better.

```{r}
qplot(log(RT), data = dual_experts, 
      fill = log(RT) > mean(log(RT)) + 3*sd(log(RT)) |
        log(RT) < mean(log(RT)) - 3*sd(log(RT)))
```

Clip these.

```{r}
lmean <- mean(log(dual_experts$RT))
lsd <- sd(log(dual_experts$RT))
dual_experts$RT[log(dual_experts$RT) > lmean + 3*lsd |
                  log(dual_experts$RT) < lmean - 3*lsd] <- NA
```

Replot in linear space just to check. 

```{r}
qplot(RT, data = dual_experts)
```

Looks good. 

## Demographics and descriptives

```{r}
kable(dual_experts %>% 
        group_by(subnum) %>% 
        summarise(n = n()) %>% 
        summarise(n = n()))
```

```{r}
kable(dual_experts %>% 
        group_by(subnum) %>% 
        summarise(RT = mean(RT, na.rm=TRUE)) %>% 
        mutate(condition = "all") %>% group_by(condition) %>%
        multi_boot_standard(col = "RT"))
```

## RT and accuracy analyses

Basic analyses.

```{r}
ms <- dual_experts %>%
  filter(abacus_correct == 1, 
         search_correct == 1) %>%
  group_by(subnum, condition) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition) %>%
  multi_boot_standard(col = "RT")

kable(ms, digits = 2)

ggplot(ms,aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) 
```

Add two other variables: bead type and number of columns. 

```{r}
ms <- dual_experts %>%
  filter(abacus_correct == 1, 
         search_correct == 1) %>%
  group_by(subnum, condition, bead_type, n_col) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, bead_type, n_col) %>%
  multi_boot_standard(col = "RT")

kable(ms, digits = 2)

ggplot(ms,aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid(bead_type ~ n_col)
```

It's clear that the effects are being driven by the 2-column displays, and especiallywith the earthly beads. (Though there are probably fewer heavenly bead trials, no?).

Order effects.

```{r}
ms <- dual_experts %>%
  filter(abacus_correct == 1, 
         search_correct == 1) %>%
  mutate(second_half = trial_num > 64) %>%
  group_by(subnum, condition, second_half) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, second_half) %>%
  multi_boot_standard(col = "RT")

kable(ms, digits = 2)

ggplot(ms,aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~second_half) + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) 
```


## Stats 

Basic LMER confirms highly significant effects for in/out of play, and leading/trailing. Could do better parameterization, but this is still very clear. More random effects don't converge. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition + 
                     (condition | subnum), 
                   data = filter(dual_experts, 
                                 search_correct == 1, 
                                 abacus_correct == 1)))$coefficients, digits = 3)
```

Now add number of columns. Doesn't converge with number of columns in random effects. This is also strong and clear, and the interactions suggest that all of this gets essentially canceled out in the three-column condition. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition * factor(n_col) + 
                     (condition | subnum), 
                   data = filter(dual_experts, 
                                 search_correct == 1, 
                                 abacus_correct == 1)))$coefficients, digits = 3)
```

Is there an order effect?

```{r}
dual_experts$second_half <- dual_experts$trial_num > 64
kable(summary(lmer(log(RT) ~ trial_num + condition * factor(n_col) * second_half + 
                     (condition | subnum), 
                   data = filter(dual_experts, 
                                 search_correct == 1, 
                                 abacus_correct == 1)))$coefficients, digits = 3)
```
 
# Experiment 2: Experts with no dual task

## Data prep

Read data. 

```{r}
single_experts_raw <- read.csv("data/Upright Single Task Expert Data w. subject IDs and order.csv")
names(single_experts_raw) <- c("bead_type", "condition", "number_requested", 
                             "X_pos","Y_pos","search_correct","RT",
                             "abacus_val","abacus_correct","n_col",
                             "subnum","outlier","trial_type",
                             "subid","n_conditions","order","subid_xexpts")
single_experts_raw %<>% 
  mutate(bead_type = factor(bead_type, 
                            levels = c(0,1), 
                            labels = c("heaven","earth")),
         condition = factor(condition, 
                            levels = c(1,2,3,4), 
                            labels = c("in play", "out of play", 
                                       "leading","trailing")))
```

Exclusions. Filter pilot participants. 

```{r}
pilot_subs <- single_experts_raw %>%
  group_by(subnum) %>%
  summarise(pilot = any(n_col == 0)) %>%
  filter(pilot) 
  
single_experts <- filter(single_experts_raw, 
                       !subnum %in% pilot_subs$subnum)
single_experts %<>% 
  group_by(subnum) %>%
  mutate(trial_num = 1:n())
```

Check to make sure we have a consistent number of trials, no training trials. 

```{r}
qplot(subnum, trial_num, data = single_experts)
```

All participants have full data. 

RT exclusions. Note that there are a few 0 RTs. What's the deal with these?

```{r}
sum(single_experts$RT == 0)
single_experts %<>% filter(RT > 0, 
                         !is.na(RT))
```

Again clip in log space. 

```{r}
qplot(log(RT), data = single_experts, 
      fill = log(RT) > mean(log(RT)) + 3*sd(log(RT)) |
        log(RT) < mean(log(RT)) - 3*sd(log(RT)))
```

Clip these.

```{r}
lmean <- mean(log(single_experts$RT))
lsd <- sd(log(single_experts$RT))
single_experts$RT[log(single_experts$RT) > lmean + 3*lsd |
                  log(single_experts$RT) < lmean - 3*lsd] <- NA
```

Replot in linear space just to check. 

```{r}
qplot(RT, data = single_experts)
```

Looks good. 

## Demographics and descriptives

```{r}
kable(single_experts %>% 
        group_by(subnum) %>% 
        summarise(n = n()) %>% 
        summarise(n = n()))
```

```{r}
kable(single_experts %>% 
        group_by(subnum) %>% 
        summarise(RT = mean(RT, na.rm=TRUE)) %>% 
        mutate(condition = "all") %>% group_by(condition) %>%
        multi_boot_standard(col = "RT"))
```

## RT and accuracy analyses

Basic analyses.

```{r}
ms <- single_experts %>%
  filter(search_correct == 1) %>%
  group_by(subnum, condition) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition) %>%
  multi_boot_standard(col = "RT")

kable(ms, digits = 2)

ggplot(ms,aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) 
```

Add two other variables: bead type and number of columns. 

```{r}
ms <- single_experts %>%
  filter(search_correct == 1) %>%
  group_by(subnum, condition, bead_type, n_col) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, bead_type, n_col) %>%
  multi_boot_standard(col = "RT")

kable(ms, digits = 2)

ggplot(ms, aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid(bead_type ~ n_col)
```

Now in this experiment, we're actually seeing effects in the three-column case. That suggests that it was the load of the three-column abacus reading that was suppressing the attentional effects, which is actually kind of nice and interesting.  

## Stats 

Same LMER as before. This time the model didn't converge with random condition effects. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition + 
                     (1 | subnum), 
                   data = filter(single_experts, 
                                 search_correct == 1)))$coefficients, 
      digits = 3)
```

Now add number of columns again. Here there are no interactions, which is clear and nice. Interestingly, now the model will converge with condition in the random effects. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition * factor(n_col) + 
                     (condition | subnum), 
                   data = filter(single_experts, 
                                 search_correct == 1)))$coefficients, digits = 3)
```
 
# Experiments 1 and 2 together

Bind everything together. Note that we filter correct search trials here rather than in models below. 

```{r}
experts <- bind_rows(filter(single_experts,
                            search_correct ==1) %>%
                       mutate(expt = "single task", 
                              group = "experts"),
                     filter(dual_experts, 
                            search_correct == 1, 
                            abacus_correct == 1) %>%
                       mutate(expt = "dual task", 
                              group = "experts")) %>%
    mutate(subid_xexpts = as.numeric(as.character(subid_xexpts)), 
           order = ifelse(order == "1", 1, ifelse(order == "N/A", NA, 2))) 
```

## Visualization

We don't learn much more this way, but we can plot everything together

```{r}
ms <- experts %>%
  group_by(subnum, condition, expt) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, expt) %>%
  multi_boot_standard(col = "RT")

ggplot(ms,aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid(~expt)
```

## Stats

Model the whole thing together. 

```{r}
kable(summary(lmer(log(RT) ~ expt * trial_num + expt * condition + 
                     (condition | subnum), 
                   data = filter(experts)))$coefficients, 
      digits = 3)
```
 
This is very interpretable: 

* the single task is faster than dual, 
* you get faster as you continue doing the tasks
* you don't improve as much with repeated trials in the single task (because you're not getting faster at reading the abacus)
* there are effects of in vs. out of play and leading vs. following
* there are no interactions with task. 

Awesome.

## Stats - Bayesian

Because there is no interaction of conditon and task, we interpret as similar attentional biases. But this is technically an inference from null. 

Thus, we move to a Bayesian framework to quantify evidence for null. First we shift to a (frequentist) ANOVA (over condition means) and then compute BFs.

```{r}
anova_data <- experts %>%
  ungroup %>%
  mutate(subnum = factor(subnum), 
         expt = factor(expt)) %>%
  group_by(expt, condition, subnum) %>%
  summarise(log_rt = mean(log(RT), na.rm=TRUE))

aov_mod <- aov(log_rt ~ expt * condition + Error(subnum), data = anova_data)

summary(aov_mod)
```

Interpretation is identical, there are main effects of experiment and condition, with no interaction. Now for BF. (Note `BayesFactor` package not compatible with `tibble`). 

```{r}
anovaBF(log_rt ~ expt * condition + subnum, 
        data = as.data.frame(anova_data), 
        whichRandom = "subnum", 
        whichModels = "top")
```

We are seeing substantial evidence in this analysis FOR the omission of `condition:experiment` (BF > 10). 

Let's try this in the `lmBF` framework as well. 

```{r}
lmbf_data <- experts %>%
  ungroup %>%
  mutate(subnum = factor(subnum), 
         expt = factor(expt), 
         log_rt = log(RT))  %>%
  filter(!is.na(log_rt)) 
  
lm_mod <- lmBF(log_rt ~ expt * trial_num + expt * condition, 
               data = as.data.frame(lmbf_data), 
               whichRandom = "subnum")
lm_mod

lm_mod_nointeraction <- lmBF(log_rt ~ expt * trial_num + expt + condition, 
               data = as.data.frame(lmbf_data), 
               whichRandom = "subnum")
lm_mod_nointeraction

lm_mod / lm_mod_nointeraction
```

Very consistent. 


## Order effects

First figure out who participated in both. You only got a subid_xexpt if you participated in both?

```{r}
xexpts <- unique(experts$subid_xexpts)
length(xexpts[!is.na(xexpts)])
```

Next, check the stats for this group. First same model as above. 

```{r}
kable(summary(lmer(log(RT) ~ expt * trial_num + expt * condition + 
                     (condition | subnum), 
                   data = filter(experts, !is.na(subid_xexpts))))$coefficients, 
      digits = 3)
```

Next, add interactions of order. 

```{r}
print("foo")
kable(summary(lmer(log(RT) ~ expt * trial_num + expt * condition * order + 
                     (condition | subnum), 
                   data = filter(experts, !is.na(subid_xexpts))))$coefficients, 
      digits = 3)
```

Hard to conclude anything from this. Let's look at the plot. 

```{r}
ms <- experts %>%
  filter(!is.na(subid_xexpts)) %>%
  group_by(subnum, condition, expt, order) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, expt, order) %>%
  multi_boot_standard(col = "RT")

ggplot(ms,aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid(order~expt)
```

# Experiment 3: Naive participants, single task

## Data prep

Read data. 

```{r}
naive_raw <- read.csv("data/UprightAdultData.csv")
names(naive_raw) <- c("bead_type", "condition", "number_requested", 
                             "X_pos","Y_pos","search_correct","RT",
                             "abacus_val","abacus_correct","n_col",
                             "subnum","outlier","trial_type", "expertise")
naive_raw %<>% 
  mutate(bead_type = factor(bead_type, 
                            levels = c(0,1), 
                            labels = c("heaven","earth")),
         condition = factor(condition, 
                            levels = c(1,2,3,4), 
                            labels = c("in play", "out of play", 
                                       "leading","trailing")))
```

Exclusions. Filter pilot participants. 

```{r}
pilot_subs <- naive_raw %>%
  group_by(subnum) %>%
  summarise(pilot = any(n_col == 0)) %>%
  filter(pilot) 
  
naive <- filter(naive_raw, 
                !subnum %in% pilot_subs$subnum)
naive %<>% 
  group_by(subnum) %>%
  mutate(trial_num = 1:n())
```

Check to make sure we have a consistent number of trials, no training trials. 

```{r}
qplot(subnum, trial_num, data = naive)
```

All participants have full data. 

RT exclusions. Again clip in log space. 

```{r}
qplot(log(RT), data = naive, 
      fill = log(RT) > mean(log(RT)) + 3*sd(log(RT)) |
        log(RT) < mean(log(RT)) - 3*sd(log(RT)))
```

Clip these.

```{r}
lmean <- mean(log(naive$RT))
lsd <- sd(log(naive$RT))
naive$RT[log(naive$RT) > lmean + 3*lsd |
           log(naive$RT) < lmean - 3*lsd] <- NA
```

Replot in linear space just to check. 

```{r}
qplot(RT, data = naive)
```

Looks good. 


## Demographics and descriptives

```{r}
kable(naive %>% 
        group_by(subnum) %>% 
        summarise(n = n()) %>% 
        summarise(n = n()))
```

```{r}
kable(naive %>% 
        group_by(subnum) %>% 
        summarise(RT = mean(RT, na.rm=TRUE)) %>% 
        mutate(condition = "all") %>% group_by(condition) %>%
        multi_boot_standard(col = "RT"))
```

## RT and accuracy analyses

Basic analyses. Summary: In this experiment, the effects are smaller, but still present, at all column levels. 

```{r}
ms <- naive %>%
  filter(search_correct == 1) %>%
  group_by(subnum, condition) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition) %>%
  multi_boot_standard(col = "RT")

kable(ms, digits = 2)

ggplot(ms,aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) 
```

Add two other variables: bead type and number of columns. 

```{r}
ms <- naive %>%
  filter(search_correct == 1) %>%
  group_by(subnum, condition, bead_type, n_col) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, bead_type, n_col) %>%
  multi_boot_standard(col = "RT")

kable(ms, digits = 2)

ggplot(ms, aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid(bead_type ~ n_col)
```

Add abacus expertise instead. 

```{r}
ms <- naive %>%
  filter(search_correct == 1) %>%
  group_by(subnum, condition, expertise) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, expertise) %>%
  multi_boot_standard(col = "RT")

kable(ms, digits = 2)

ggplot(ms, aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid(. ~ expertise)
```

## Stats 

Same LMER as in the previous two, with the full random effects structure. This model shows both effects, as before. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition + 
                     (condition | subnum), 
                   data = filter(naive, 
                                 search_correct == 1)))$coefficients, 
      digits = 3)
```

Now add number of columns again. Here again there are no interactions, suggesting that column didn't affect matters. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition * factor(n_col) + 
                     (condition | subnum), 
                   data = filter(naive, 
                                 search_correct == 1)))$coefficients, digits = 3)
```

And check for interactions of expertise level. First with expertise as a continuous variable. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition * expertise + 
                     (condition | subnum), 
                   data = filter(naive, 
                                 search_correct == 1)))$coefficients, digits = 3)
```

Now with expertise as a factor. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition * factor(expertise) + 
                     (condition | subnum), 
                   data = filter(naive, 
                                 search_correct == 1)))$coefficients, digits = 3)
```

In both cases, we see a slightly bigger effect of leading zeros being slower for the participants with more abacus exposure. This is not totally unreasonable, but it's a small effect. 

Finally, check a followup model for only zero expertise subjects. Does not converge with random slope.

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition + 
                     (1 | subnum), 
                   data = filter(naive, 
                                 expertise == 0,
                                 search_correct == 1)))$coefficients, digits = 3)
```

## Bayesian stats

We focus here on the question of expertise interactions.

```{r}
# model of interest
# log(RT) ~ trial_num + condition * expertise + 
#                      (condition | subnum), 
#                    data = filter(naive, 
#                                  search_correct == 1)


lmbf_data <- naive %>%
  filter(search_correct == 1) %>%
  ungroup %>%
  mutate(subnum = factor(subnum), 
         log_rt = log(RT)) %>%
  filter(!is.na(log_rt))
  
lm_mod <- lmBF(log_rt ~ trial_num + condition * expertise, 
               data = as.data.frame(lmbf_data), 
               whichRandom = "subnum")
lm_mod

lm_mod_nointeraction <- lmBF(log_rt ~ trial_num + condition + expertise, 
               data = as.data.frame(lmbf_data), 
               whichRandom = "subnum")
lm_mod_nointeraction

lm_mod / lm_mod_nointeraction
```


# Experiments 2 and 3 

Bind all data.

```{r}
d <- bind_rows(filter(naive, 
                      search_correct == 1) %>%
                 mutate(expt = "single task",
                        group = "naive"), 
               experts)
```

Now plot.

```{r}
ms <- d %>%
  filter(expt == "single task") %>%
  group_by(subnum, condition, group) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, group) %>%
  multi_boot_standard(col = "RT")

ggplot(ms, aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid( ~ group)
```

And a statistical model.

```{r}
kable(summary(lmer(log(RT) ~ trial_num + condition * group + 
                     (condition | subnum), 
                   data = filter(d, 
                                 expt == "single task")))$coefficients, 
      digits = 3)
```
 
Summary - experts are *way* slower than naive participants, even when they don't have the dual task. That's interesting, I think - they are still processing the abacus somehow prior to searching.

There's not much in the way of interactions of the effects with group, with one exception. The naive participants don't show as big an "out of play" effect as the experts, trending with p = `r 2*pnorm(-1.95)`. So there may be some small difference there. 

## Bayesian version

```{r}
# model of interest
# lmer(log(RT) ~ trial_num + condition * group + 
#                      (condition | subnum), 
#                    data = filter(d, 
#                                  expt == "single task")

lmbf_data <- d %>%
  filter(expt == "single task") %>%
  ungroup %>%
  mutate(subnum = factor(subnum), 
         log_rt = log(RT), 
         group = factor(group)) %>%
  filter(!is.na(log_rt))
  
lm_mod <- lmBF(log_rt ~ trial_num + condition * group, 
               data = as.data.frame(lmbf_data), 
               whichRandom = "subnum")
lm_mod

lm_mod_nointeraction <- lmBF(log_rt ~ trial_num + condition + group, 
               data = as.data.frame(lmbf_data), 
               whichRandom = "subnum")
lm_mod_nointeraction

lm_mod / lm_mod_nointeraction
```
 
# All data

## Plots for paper

```{r}
ms <- d %>%
  group_by(subnum, condition, expt, expertise, group) %>%
  summarise(RT = mean(RT, na.rm=TRUE)) %>%
  group_by(condition, expt, expertise, group) %>%
  multi_boot_standard(col = "RT")
```

First in-play/out-of-play.

```{r}
ggplot(filter(ms, group=="experts", 
              condition == "in play" | condition == "out of play"), 
       aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid( ~ expt) + 
  theme_mikabr() + 
  scale_fill_solarized()
```

Then trailing/leading.

```{r}
ggplot(filter(ms, group=="experts", 
              condition == "leading" | condition == "trailing"), 
       aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid( ~ expt) + 
  theme_mikabr() + 
  scale_fill_solarized()
```

Then the same in/out of play by expertise.

```{r}
ggplot(filter(ms, group=="naive", 
              condition == "in play" | condition == "out of play"), 
       aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid( ~ expertise) + 
  theme_mikabr() + 
  scale_fill_solarized()
```

and leading/trailing by expertise.

```{r}
ms$expertise <- factor(ms$expertise, levels = c(0, 1, 2), labels = c("No experience","Recognition only","Experience using"))
ggplot(filter(ms, group=="naive", 
              condition == "leading" | condition == "trailing"), 
       aes(x = condition, y = mean, fill = condition)) + 
  geom_bar(stat = "identity") + 
  geom_linerange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  facet_grid( ~ expertise) + 
  theme_mikabr() + 
  scale_fill_solarized()
```

## Basic stats

Consolidate all data into a single model. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num * group * expt + 
                     condition * group * expt + 
                     (condition | subnum), 
                   data = d))$coefficients, 
      digits = 3)
```

In the full model we see all the effects holding up, with not much evidence for interactions of expertise or experiment type. That's pretty much exactly what we thought was going on. 

## Post-hoc analysis: Targets closer to the beam

Does position mediate the "in play/out of play" effect?

First, the baseline model for this analysis: only earthly beads (since heavenly bead position and "in play" is confounded. 

There's an interesting decision to make here in the random effects. I think it's best to go with no condition or Y_pos random effect both for convergence reasons and because it's hard theoretically to interpret when you have all the interactions here. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num * group * expt + 
                     condition * group * expt + 
                     (1 | subnum), 
                   data = filter(d, 
                                 condition %in% c("in play","out of play"),
                                 bead_type == "earth")))$coefficients, 
      digits = 3)

```

Next, add vertical position as a predictor. 

```{r}
kable(summary(lmer(log(RT) ~ trial_num * group * expt + 
                     condition * group * expt + 
                     Y_pos * group * expt + 
                     (1 | subnum), 
                   data = filter(d, 
                                 condition %in% c("in play","out of play"),
                                 bead_type == "earth")))$coefficients, 
      digits = 3)

```

Now we see a significant effect of Y position with no remaining effect of "out of play." Check for interactions? 

```{r}
kable(summary(lmer(log(RT) ~ trial_num * group * expt + 
                     Y_pos * group * expt * condition + 
                     (1 | subnum), 
                   data = filter(d, 
                                 condition %in% c("in play","out of play"),
                                 bead_type == "earth")))$coefficients, 
      digits = 3)

```

Interestingly, we are seeing some three-way interactions, but these are a bit hard to interpret. Let's subset to Experiments 1, 2, and 3.

```{r}
kable(summary(lmer(log(RT) ~ trial_num + 
                     Y_pos * condition + 
                     (1 | subnum), 
                   data = filter(d, 
                                 group == "experts", 
                                 expt == "dual task",
                                 condition %in% c("in play","out of play"),
                                 bead_type == "earth")))$coefficients, 
      digits = 3)

kable(summary(lmer(log(RT) ~ trial_num + 
                     Y_pos * condition + 
                     (1 | subnum), 
                   data = filter(d, 
                                 group == "experts", 
                                 expt == "single task",
                                 condition %in% c("in play","out of play"),
                                 bead_type == "earth")))$coefficients, 
      digits = 3)

kable(summary(lmer(log(RT) ~ trial_num + 
                     Y_pos * condition + 
                     (1 | subnum), 
                   data = filter(d, 
                                 group == "naive", 
                                 expt == "single task",
                                 condition %in% c("in play","out of play"),
                                 bead_type == "earth")))$coefficients, 
      digits = 3)

```

So we see the same unpredicted effect in Experiment 2 as in the previous analysis. 

## Post-hoc analysis: X position / RVF effects

`X_pos` is 1 for left-most position. `VF` is a variable that maps further right displays to higher numbers. 

```{r}
d$VF <- d$X_pos - ((d$n_col / 2) + .5)
ggplot(d, 
       aes(x = VF, y = log(RT), col = factor(n_col))) + 
  geom_jitter(alpha = .02) + 
  geom_smooth(method = "lm") + 
  facet_grid(condition ~ expt) + 
  ylim(c(0,2)) + 
  theme_mikabr() 
```

Model. 

```{r}
xpos_data <- d %>%
  filter(group == "experts", 
         expt == "single task",
         condition %in% c("in play",
                          "out of play")) %>%
  mutate(x_pos_normalized = -X_pos / n_col)

kable(summary(lmer(log(RT) ~ trial_num + 
                     VF * factor(n_col) + 
                     (1 | subnum),  data = xpos_data))$coefficients, 
              digits = 3)
```

